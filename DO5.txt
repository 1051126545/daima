import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import geopandas as gpd
import cartopy.crs as ccrs
import matplotlib.ticker as mticker
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold
from imblearn.pipeline import Pipeline as imbpipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from matplotlib.lines import Line2D
from scipy.interpolate import griddata
import shap
import matplotlib
from imblearn.over_sampling import SMOTE
from shapely.geometry import Polygon, MultiPolygon
from shapely.ops import unary_union
from shapely.ops import transform  # âœ… ç¡®ä¿è¿™è¡Œæ²¡æœ‰è¢«æ³¨é‡Š
import pyproj
from shapely.geometry import Polygon
from shapely.ops import unary_union
from shapely.geometry import Point, Polygon  # å¯¼å…¥æ‰€éœ€çš„å‡ ä½•ç±»å‹
from pyproj import Transformer
# -------------------------------
# âœ… ç»Ÿä¸€å­—ä½“è®¾ç½®ï¼šæ”¯æŒä¸­è‹±æ–‡çš„é»‘ä½“
# -------------------------------
matplotlib.use('Agg')  # å¿…é¡»åœ¨ plt ä¹‹å‰

# è®¾ç½®ä¸­æ–‡å­—ä½“ä¸ºé»‘ä½“ï¼Œæ”¯æŒä¸­æ–‡å’Œå…¨è§’ç¬¦å·
plt.rcParams['font.sans-serif'] = [
    'SimHei',           # é»‘ä½“ï¼ˆWindowsï¼‰
    'Microsoft YaHei',  # å¾®è½¯é›…é»‘ï¼ˆå¤‡ç”¨ï¼‰
    'DejaVu Sans',      # è·¨å¹³å°å¤‡é€‰ï¼ˆæ”¯æŒè‹±æ–‡ã€æ‹¬å·ç­‰ï¼‰
    'Arial',
    'sans-serif'
]
plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# å…¨å±€å­—ä½“å¤§å°ä¸æ ·å¼
plt.rcParams.update({
    'font.size': 12,                # å…¨å±€å­—ä½“å¤§å°
    'axes.labelsize': 12,           # åæ ‡è½´æ ‡ç­¾
    'xtick.labelsize': 12,          # xè½´åˆ»åº¦
    'ytick.labelsize': 12,          # yè½´åˆ»åº¦
    'legend.fontsize': 12,          # å›¾ä¾‹
    'figure.titlesize': 10,         # å›¾æ ‡é¢˜å¤§å°
    'figure.titleweight': 'bold',   # å›¾æ ‡é¢˜åŠ ç²—
    'savefig.dpi': 300,             # é«˜æ¸…è¾“å‡º
    'savefig.bbox': 'tight',        # ç´§å‡‘è¾¹è·
    'figure.figsize': (8, 6),       # é»˜è®¤å›¾åƒå¤§å°
    'axes.grid': False              # å…³é—­ç½‘æ ¼ï¼ˆå¯é€‰ï¼‰
})

output_img_dir = "G:/years/6month/RESULT/6/ALL"#5.6
os.makedirs(output_img_dir, exist_ok=True)

file_path = "G:/years/6month/BScentral.xlsx"
df = pd.read_excel(file_path, sheet_name='Sheet1')#2014-2024

non_feature_cols = ['do', 'time', 'station', 'longitude', 'latitude']
X = df.drop(columns=non_feature_cols)
y = df['do'].apply(lambda x: 1 if x <= 4 else 0)  # do <= 4 è¡¨ç¤ºä½æ°§äº‹ä»¶

original_feature_names = X.columns.tolist()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("è®­ç»ƒé›†ä¸­çš„ç±»åˆ«åˆ†å¸ƒ:")
print(y_train.value_counts())

pipeline = imbpipeline([
    ('imputer', SimpleImputer(strategy='mean')),  # ç¼ºå¤±å€¼å¡«å……
    ('scaler', StandardScaler()),                 # æ ‡å‡†åŒ–
    ('smote', SMOTE(random_state=42)),            # ä½¿ç”¨ imblearn çš„ SMOTE
    ('model', RandomForestClassifier(random_state=42, class_weight='balanced'))
])

# å‚æ•°ç½‘æ ¼
param_grid = {
    'model__max_depth': [5, 7],
    'model__min_samples_leaf': [2, 5],
    'model__n_estimators': [200]
}

# ç½‘æ ¼æœç´¢
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    scoring='f1',
    cv=5,
    n_jobs=-1,
    verbose=1
)
grid_search.fit(X_train, y_train)

# æœ€ä½³æ¨¡å‹
best_pipeline = grid_search.best_estimator_
print("âœ… æœ€ä¼˜å‚æ•°:", grid_search.best_params_)

# æ¦‚ç‡é¢„æµ‹
y_score = best_pipeline.predict_proba(X_test)[:, 1]
y_pred = (y_score >= 0.5).astype(int)  # é»˜è®¤é˜ˆå€¼

# è‡ªåŠ¨æœç´¢æœ€ä½³é˜ˆå€¼
thresholds = np.linspace(0.1, 0.5, 20)
best_threshold = 0.5
best_f1 = 0
for t in thresholds:
    y_pred_t = (y_score >= t).astype(int)
    f1 = f1_score(y_test, y_pred_t)
    if f1 > best_f1:
        best_f1 = f1
        best_threshold = t
print(f"\næœ€ä½³é˜ˆå€¼: {best_threshold:.2f}, æœ€ä½³ F1 Score: {best_f1:.4f}")

# ä½¿ç”¨æœ€ä½³é˜ˆå€¼é¢„æµ‹
y_pred_best = (y_score >= best_threshold).astype(int)

# æ€§èƒ½è¯„ä¼°å‡½æ•°
def evaluate_model(y_true, y_pred, y_score=None, name="æ¨¡å‹"):
    print(f"\n=== {name} æ€§èƒ½è¯„ä¼° ===")
    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    if y_score is not None:
        auc = roc_auc_score(y_true, y_score)
    else:
        auc = float('nan')
    print("confusion matrix:")
    print(cm)
    print(f"å‡†ç¡®ç‡ Accuracy:  {acc:.4f}")
    print(f"ç²¾ç¡®ç‡ Precision: {prec:.4f}")
    print(f"å¬å›ç‡ Recall:    {rec:.4f}")
    print(f"F1 Score:        {f1:.4f}")
    print(f"AUC Score:       {auc:.4f}")
    fig_path = os.path.join(output_img_dir, f"confusion_matrix_{name}.png")
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['Predicted 0', 'Predicted 1'],
                yticklabels=['Actual 0', 'Actual 1'])
    plt.title(f"{name} confusion matrix")
    #plt.xlabel("é¢„æµ‹å€¼")
    #plt.ylabel("çœŸå®å€¼")
    plt.tight_layout()
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜è‡³: {fig_path}")
    return {
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1': f1,
        'auc': auc}

# è¯„ä¼°é»˜è®¤é˜ˆå€¼å’Œæœ€ä½³é˜ˆå€¼æ¨¡å‹
#results = evaluate_model(y_test, y_pred, y_score, name="é»˜è®¤é˜ˆå€¼æ¨¡å‹")
results = evaluate_model(y_test, y_pred, y_score, name="Default threshold model")
#custom_results = evaluate_model(y_test, y_pred_best, y_score, name=f"æœ€ä½³é˜ˆå€¼({best_threshold:.2f})æ¨¡å‹")
custom_results = evaluate_model(y_test, y_pred_best, y_score, name=f"Best threshold ({best_threshold:.2f}) model")
# ROCæ›²çº¿
fpr, tpr, thresholds_roc = roc_curve(y_test, y_score)
roc_fig_path = os.path.join(output_img_dir, "roc_curve.png")
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_score):.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig(roc_fig_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"âœ… ROCæ›²çº¿å›¾å·²ä¿å­˜è‡³: {roc_fig_path}")

# ç‰¹å¾é‡è¦æ€§
model = best_pipeline.named_steps['model']
importances = model.feature_importances_
feature_names = original_feature_names  # è¿™æ˜¯ä¸€ä¸ª list

# ç‰¹å¾é‡è¦æ€§å›¾
feature_fig_path = os.path.join(output_img_dir, "feature_importance.png")
pd.Series(importances, index=feature_names).sort_values().plot(kind='barh', figsize=(10, 6))
plt.title("Feature importanceï¼ˆRandom Forestï¼‰")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.tight_layout()
plt.savefig(feature_fig_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"âœ… ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜è‡³: {feature_fig_path}")

# SHAP è§£é‡Šåˆ†æ
print("\nğŸ“Š å¼€å§‹ç”Ÿæˆ SHAP è§£é‡Šå›¾...")

# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„å¤„ç†ï¼ˆä»…ä½¿ç”¨ imputer å’Œ scalerï¼‰
X_test_processed = best_pipeline.named_steps['imputer'].transform(X_test)
X_test_processed = best_pipeline.named_steps['scaler'].transform(X_test_processed)

# åˆ›å»º DataFrameï¼Œä½¿ç”¨åŸå§‹ç‰¹å¾å
X_test_all_features = pd.DataFrame(X_test_processed, columns=original_feature_names)

# è·å–æ¨¡å‹éƒ¨åˆ†
model = best_pipeline.named_steps['model']

# è®¡ç®— SHAP å€¼ï¼Œç¡®ä¿æ•°æ®ä¸æ¨¡å‹è¾“å…¥ä¸€è‡´
explainer = shap.TreeExplainer(model, check_additivity=False)  # ç¦ç”¨åŠ æ³•æ€§æ£€æŸ¥
shap_values = explainer.shap_values(X_test_all_features)

# 1. SHAP æ‘˜è¦å›¾ï¼ˆSummary Plotï¼‰
shap.summary_plot(shap_values[1], X_test_all_features, show=False)
plt.savefig(os.path.join(output_img_dir, "shap_summary_plot.png"), dpi=300, bbox_inches='tight')
plt.close()
print("âœ… SHAP æ‘˜è¦å›¾å·²ä¿å­˜")

# 2. æ¯ä¸ªç‰¹å¾çš„ä¾èµ–å›¾ï¼ˆDependence Plotï¼‰
for feature_name in original_feature_names:
    plt.figure(figsize=(8, 6))
    shap.dependence_plot(feature_name, shap_values[1], X_test_all_features, show=False)
    plt.savefig(os.path.join(output_img_dir, f"shap_dependence_plot_{feature_name}.png"), dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… SHAP ä¾èµ–å›¾ï¼ˆ{feature_name}ï¼‰å·²ä¿å­˜")

y_train_score = best_pipeline.predict_proba(X_train)[:, 1]
y_train_pred = (y_train_score >= best_threshold).astype(int)
df_train = X_train.copy()
df_train['çœŸå®æ ‡ç­¾'] = y_train.values
df_train['é¢„æµ‹æ¦‚ç‡_è®­ç»ƒé›†'] = y_train_score
df_train['é¢„æµ‹ç»“æœ_è®­ç»ƒé›†'] = y_train_pred
print("\n=== æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ€§èƒ½ ===")
train_results = evaluate_model(
    y_train,
    y_train_pred,
    y_train_score,
    name="è®­ç»ƒé›†æ¨¡å‹"
)
train_output_path = "G:/years/6month/RESULT/6/ALL/è®­ç»ƒé›†é¢„æµ‹ç»“æœ.xlsx"
df_train.to_excel(train_output_path, index=False)
print(f"âœ… è®­ç»ƒé›†é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {train_output_path}")
scoring = {
    'accuracy': 'accuracy',
    'precision': 'precision',
    'recall': 'recall',
    'f1': 'f1',
    'roc_auc': 'roc_auc'
}
cv_results = cross_validate(
    best_pipeline,
    X_train,  # ä½¿ç”¨è®­ç»ƒé›†æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯
    y_train,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring=scoring,
    return_train_score=False,
    n_jobs=-1
)
print("\n=== äº¤å‰éªŒè¯ç»“æœï¼ˆè®­ç»ƒé›†ï¼‰ ===")
for metric in scoring:
    scores = cv_results[f'test_{metric}']
    print(f"{metric}: {scores.mean():.4f} Â± {scores.std():.4f}")
    print(f"  æ¯æŠ˜å¾—åˆ†: {scores}")
test_indices = X_test.index
unique_sites = df.loc[test_indices, ['station', 'latitude', 'longitude', 'do']].copy()
unique_sites['çœŸå®æ ‡ç­¾'] = unique_sites['do'].apply(lambda x: 1 if x <= 4 else 0)
unique_sites['é¢„æµ‹ç»“æœ'] = y_pred_best
shapefile_path = "G:/years/2017/bou1_4p.shp"
try:
    gdf_shape = gpd.read_file(shapefile_path)
except UnicodeDecodeError:
    print("âš ï¸ UTF-8 è§£ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ GBK ç¼–ç åŠ è½½ Shapefile")
    gdf_shape = gpd.read_file(shapefile_path, encoding='gbk')
import matplotlib.ticker as mticker
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
map_output_png = "G:/years/6month/RESULT/6/ALL/é¢„è­¦åœ°å›¾å¯è§†åŒ–_with_legend_comparison.png"
min_lon, max_lon = unique_sites['longitude'].min() - 1, unique_sites['longitude'].max() + 1
min_lat, max_lat = unique_sites['latitude'].min() - 1, unique_sites['latitude'].max() + 1

fig, axes = plt.subplots(1, 2, figsize=(18, 10), subplot_kw={'projection': ccrs.PlateCarree()})
ax1, ax2 = axes

def setup_ax(ax):
    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())
    gdf_shape.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.5)

    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,
                      linewidth=1, color='gray', alpha=0.5, linestyle='--')
    gl.top_labels = False
    gl.right_labels = False
    gl.xlabel_style = {'size': 16, 'color': 'black'}
    gl.ylabel_style = {'size': 16, 'color': 'black'}

    gl.xformatter = LONGITUDE_FORMATTER
    gl.yformatter = LATITUDE_FORMATTER

    # è®¾ç½®æ¯ 1 åº¦ç”»ä¸€æ¡çº¿ï¼Œå¯æ”¹ä¸º 0.5 æˆ– 2 ç­‰
    gl.xlocator = mticker.FixedLocator(np.arange(np.floor(min_lon), np.ceil(max_lon), 1))
    gl.ylocator = mticker.FixedLocator(np.arange(np.floor(min_lat), np.ceil(max_lat), 1))

legend_elements = [
    plt.Line2D([0], [0], marker='o', color='w', label='Normalï¼ˆ0ï¼‰',
               markerfacecolor='blue', markersize=12),
    plt.Line2D([0], [0], marker='o', color='w', label='Hypoxiaï¼ˆ1ï¼‰',
               markerfacecolor='red', markersize=12)
]

setup_ax(ax1)
#ax1.set_title("å›¾1: çœŸå®ä½æ°§äº‹ä»¶åˆ†å¸ƒï¼ˆçœŸå®æ ‡ç­¾ï¼‰", fontsize=14)
ax1.set_title(" Real hypoxia distribution (real label)", fontsize=16)
for _, row in unique_sites.iterrows():
    color = 'blue' if row['çœŸå®æ ‡ç­¾'] == 0 else 'red'
    ax1.plot(row['longitude'], row['latitude'], 'o',
             color=color, markersize=10, alpha=0.8,
             transform=ccrs.Geodetic())
ax1.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.02, 0.95), title="Category")#ç±»åˆ«

setup_ax(ax2)
#ax2.set_title("å›¾2: æ¨¡å‹é¢„æµ‹ä½æ°§äº‹ä»¶åˆ†å¸ƒï¼ˆé¢„æµ‹ç»“æœï¼‰", fontsize=14)
ax2.set_title(" Model prediction of hypoxia distribution (prediction labelï¼‰", fontsize=16)
for _, row in unique_sites.iterrows():
    color = 'blue' if row['é¢„æµ‹ç»“æœ'] == 0 else 'red'
    ax2.plot(row['longitude'], row['latitude'], 'o',
             color=color, markersize=10, alpha=0.8,
             transform=ccrs.Geodetic())

plt.tight_layout()
plt.savefig(map_output_png, dpi=300, bbox_inches='tight')
plt.close()
print(f"âœ… å¯¹æ¯”åœ°å›¾å·²ä¿å­˜è‡³: {map_output_png}")
plt.close()

new_sheet_name = 'Sheet7'#éªŒè¯é›†#12.13.14-2022.2020.2019å¹´æ— æ°”æ¸©ï¼Œæˆå›¾çš„sheet
df_new = pd.read_excel(file_path, sheet_name=new_sheet_name)
original_df_new = df_new.copy()

X_new = df_new[feature_names]

if 'do' in df_new.columns:
    y_new_true = df_new['do'].apply(lambda x: 1 if x <= 4 else 0)
else:
    y_new_true = None

y_new_score = best_pipeline.predict_proba(X_new)[:, 1]

best_threshold_sheet7 = 0.5
best_f1_sheet7 = 0
thresholds = np.linspace(0.1, 0.9, 50)

if y_new_true is not None:
    for threshold in thresholds:
        y_pred_t = (y_new_score >= threshold).astype(int)
        f1 = f1_score(y_new_true, y_pred_t)
        if f1 > best_f1_sheet7:
            best_f1_sheet7 = f1
            best_threshold_sheet7 = threshold
    print(f"\nâœ… Sheet æœ€ä½³é˜ˆå€¼: {best_threshold_sheet7:.2f}, æœ€ä½³ F1 Score: {best_f1_sheet7:.4f}")

    y_new_pred_sheet7 = (y_new_score >= best_threshold_sheet7).astype(int)
else:
    best_threshold_sheet7 = best_threshold
    y_new_pred_sheet7 = (y_new_score >= best_threshold_sheet7).astype(int)

df_new_output = original_df_new[['station', 'latitude', 'longitude']].copy()
df_new_output['çœŸå®æ ‡ç­¾'] = y_new_true if y_new_true is not None else np.nan
df_new_output['é¢„æµ‹æ¦‚ç‡'] = y_new_score
df_new_output['é¢„æµ‹ç»“æœ'] = y_new_pred_sheet7

output_new_sheet_path = os.path.join(output_img_dir, f"æ–°æ•°æ®é¢„æµ‹ç»“æœ_{new_sheet_name}.xlsx")
df_new_output.to_excel(output_new_sheet_path, index=False)
print(f"\nâœ… æ–°æ•°æ®é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {output_new_sheet_path}")

if y_new_true is not None:
    print(f"\nğŸ“Š æ–°æ•°æ® ({new_sheet_name}) ä¸Šçš„æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼š")

    custom_results_sheet7 = evaluate_model(
        y_new_true,
        y_new_pred_sheet7,
        y_new_score,
        name=f"{new_sheet_name} æœ€ä½³é˜ˆå€¼({best_threshold_sheet7:.2f})æ¨¡å‹"
    )

import os
import numpy as np
import matplotlib.pyplot as plt
from shapely.ops import unary_union
import geopandas as gpd
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
#from matplotlib.ticker import mticker
import matplotlib.ticker as ticker
# å‡è®¾ df_new_output å’Œå…¶ä»–å¿…è¦çš„å˜é‡å·²ç»å®šä¹‰å’Œèµ‹å€¼

if 'latitude' in df_new_output.columns and 'longitude' in df_new_output.columns:
    # å®šä¹‰è¾“å‡ºè·¯å¾„
    map_output_new_path = os.path.join(output_img_dir, f"é¢„è­¦åœ°å›¾å¯è§†åŒ–_{new_sheet_name}.png")

    try:
        # åŠ è½½shapefile
        gdf_shape = gpd.read_file(shapefile_path)
    except UnicodeDecodeError:
        print("âš ï¸ UTF-8 è§£ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ GBK ç¼–ç åŠ è½½ Shapefile")
        gdf_shape = gpd.read_file(shapefile_path, encoding='gbk')

    # ç¡®ä¿shapefileåŒ…å«æœ‰æ•ˆçš„Polygonæˆ–å¤šè¾¹å½¢å‡ ä½•ä½“
    if gdf_shape.geom_type.isin(['Polygon', 'MultiPolygon']).all():
        ocean_polygon = unary_union([geom for geom in gdf_shape.geometry if geom.is_valid])
    else:
        raise ValueError("Shapefile must contain Polygon or MultiPolygon geometries for masking.")

    # è‡ªåŠ¨è®¡ç®—åœ°å›¾çš„æ˜¾ç¤ºèŒƒå›´
    min_lon, max_lon = df_new_output['longitude'].min() - 0.5, df_new_output['longitude'].max() + 0.5#è°ƒæ•´èŒƒå›´
    min_lat, max_lat = df_new_output['latitude'].min() - 0.5, df_new_output['latitude'].max() + 0.5

    # åˆ›å»ºåœ°å›¾
    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})
    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())

    # ç»˜åˆ¶shapefile
    gdf_shape.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.5)

    # æ·»åŠ ç½‘æ ¼çº¿
    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,
                      linewidth=1, color='gray', alpha=0.5, linestyle='--')
    gl.top_labels = False
    gl.right_labels = False
    gl.xlabel_style = {'size': 15, 'color': 'black'}
    gl.ylabel_style = {'size': 15, 'color': 'black'}
    gl.xformatter = LONGITUDE_FORMATTER
    gl.yformatter = LATITUDE_FORMATTER
    gl.xlocator = mticker.FixedLocator(np.arange(np.floor(min_lon), np.ceil(max_lon), 1))
    gl.ylocator = mticker.FixedLocator(np.arange(np.floor(min_lat), np.ceil(max_lat), 1))

    # å›¾ä¾‹è®¾ç½®
    legend_elements = [
        plt.Line2D([0], [0], marker='o', color='w', label='Normalï¼ˆ0ï¼‰',
                   markerfacecolor='blue', markersize=12),
        plt.Line2D([0], [0], marker='o', color='w', label='Hypoxiaï¼ˆ1ï¼‰',
                   markerfacecolor='red', markersize=12)
    ]

    # ç»˜åˆ¶ç«™ç‚¹
    for _, row in df_new_output.iterrows():
        color = 'blue' if row['é¢„æµ‹ç»“æœ'] == 0 else 'red'
        ax.plot(row['longitude'], row['latitude'], 'o',
                color=color, markersize=10, alpha=0.8,
                transform=ccrs.Geodetic())

    # æ·»åŠ å›¾ä¾‹å’Œæ ‡é¢˜
    ax.legend(handles=legend_elements, loc='upper right', title="Predictive category")
    plt.title(f"{new_sheet_name} Visualization of prediction results")

    # ä¿å­˜å›¾åƒ
    plt.tight_layout()
    plt.savefig(map_output_new_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… åœ°å›¾å·²ä¿å­˜è‡³: {map_output_new_path}")
# 3. ç²¾ç¡®æ’å€¼å›¾ + æ¸¤æµ·æµ·åŸŸä¸¥æ ¼æ©è†œï¼ˆè®ºæ–‡çº§å¯è§†åŒ–ï¼‰â€”â€” æœ€ç»ˆä¼˜åŒ–ç‰ˆ
from shapely.geometry import Point
import xarray as xr
import rioxarray
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)
print("gdf_shape å‡ ä½•ç±»å‹:")
print(gdf_shape.geometry.geom_type.value_counts())
print("gdf_shape bounds (min_lon, min_lat, max_lon, max_lat):")
print(gdf_shape.total_bounds)  # [minx, miny, maxx, maxy]
# æå–åæ ‡ä¸é¢„æµ‹æ¦‚ç‡
lon = df_new_output['longitude'].values
lat = df_new_output['latitude'].values
z = df_new_output['é¢„æµ‹æ¦‚ç‡'].values

min_lon, max_lon = df_new_output['longitude'].min() - 0.2, df_new_output['longitude'].max() + 0.2
min_lat, max_lat = df_new_output['latitude'].min() - 0.2, df_new_output['latitude'].max() + 0.2

resolution = 500
grid_lon = np.linspace(min_lon, max_lon, resolution)
grid_lat = np.linspace(min_lat, max_lat, resolution)
grid_lon_2d, grid_lat_2d = np.meshgrid(grid_lon, grid_lat)

# æ’å€¼
try:
    grid_z = griddata(points=np.column_stack((lon, lat)), values=z,
                      xi=np.column_stack((grid_lon_2d.ravel(), grid_lat_2d.ravel())), method='cubic')
except Exception as e:
    print(f"âš ï¸ cubic æ’å€¼å¤±è´¥: {e}ï¼Œæ”¹ç”¨ linear")
    grid_z = griddata(points=np.column_stack((lon, lat)), values=z,
                      xi=np.column_stack((grid_lon_2d.ravel(), grid_lat_2d.ravel())), method='linear')
grid_z = grid_z.reshape(grid_lon_2d.shape)

# è½¬ä¸º xarray å¹¶å†™ CRS
da = xr.DataArray(
    data=grid_z[np.newaxis, :, :],
    dims=["band", "y", "x"],
    coords={"band": [1], "y": grid_lat, "x": grid_lon},
    attrs={
        "transform": (grid_lon[1] - grid_lon[0], 0, grid_lon[0],
                      0, grid_lat[1] - grid_lat[0], grid_lat[0]),
        "crs": "EPSG:4326"
    }
)
da.rio.write_crs("EPSG:4326", inplace=True)

from shapely.ops import unary_union
import numpy as np

# æ„å»ºæµ·æ´‹å¤šè¾¹å½¢ - å‡è®¾ gdf_shape åŒ…å«æ¸¤æµ·æµ·åŸŸçš„é™†åœ°è¾¹ç•Œ
polys = [geom for geom in gdf_shape.geometry if geom.is_valid]

# å¦‚æœæœ‰ MultiPolygon ç±»å‹çš„æ•°æ®ï¼Œå…ˆå°†å…¶è§£åŒ…æˆ Polygon åˆ—è¡¨
polygons = []
for geom in polys:
    if geom.geom_type == 'Polygon':
        polygons.append(geom)
    elif geom.geom_type == 'MultiPolygon':
        polygons.extend(geom.geoms)

# ä½¿ç”¨ unary_union åˆå¹¶æ‰€æœ‰å¤šè¾¹å½¢ï¼Œé¿å…é‡å¤ç‚¹æˆ–é‡å åŒºåŸŸ
ocean_polygon = unary_union(polygons)

try:
    # ä½¿ç”¨ rioxarray æ©è†œï¼ˆä»…ä¿ç•™æµ·æ´‹å†…éƒ¨ï¼‰
    da_masked = da.rio.clip([ocean_polygon], drop=False, invert=True)
    masked_da = da_masked[0].values  # æå– numpy æ•°ç»„ï¼Œé¿å…åæ ‡é—®é¢˜
    print("âœ… æˆåŠŸä½¿ç”¨ rioxarray æ©è†œï¼ˆå»é™¤é™†åœ°ï¼Œä¿ç•™æµ·æ´‹ï¼‰")
except Exception as e:
    print(f"âš ï¸ rioxarray æ©è†œå¤±è´¥: {e}ï¼Œä½¿ç”¨ä¼ ç»Ÿæ©è†œå›é€€")

    # åˆ›å»ºæ©è†œï¼šTrue è¡¨ç¤ºè¦ maskï¼ˆéšè—ï¼‰
    mask = np.ones(grid_z.shape, dtype=bool)
    # å¿«é€Ÿé‡‡æ ·åˆ¤æ–­æ˜¯å¦åœ¨æµ·æ´‹å†…
    for i in range(0, grid_lon_2d.shape[0], 5):
        for j in range(0, grid_lon_2d.shape[1], 5):
            point = Point(grid_lon_2d[i, j], grid_lat_2d[i, j])
            if not ocean_polygon.contains(point):  # ä¸åœ¨ä»»ä½•é™†åœ°å¤šè¾¹å½¢å†…å³ä¸ºæµ·æ´‹
                # æ ‡è®°é™„è¿‘åŒºåŸŸä¸ºâ€œä¸æ©è†œâ€
                i_start, i_end = max(0, i-2), min(grid_z.shape[0], i+3)
                j_start, j_end = max(0, j-2), min(grid_z.shape[1], j+3)
                mask[i_start:i_end, j_start:j_end] = False
    # æ‰©å±• mask åˆ°å…¨å›¾
    mask_full = np.repeat(np.repeat(mask[::5, ::5], 5, axis=0), 5, axis=1)
    mask_full = mask_full[:grid_z.shape[0], :grid_z.shape[1]]
    masked_da = np.ma.masked_array(grid_z, mask_full)

# å¼€å§‹ç»˜å›¾
# fig, ax = plt.subplots(figsize=(10, 9), subplot_kw={'projection': ccrs.PlateCarree()})
# ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())
# gdf_shape.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.8, zorder=1)
map_output_interpolate_path = os.path.join(output_img_dir, f"é¢„è­¦åœ°å›¾å¯è§†åŒ–_interpolated_{new_sheet_name}.png")
fig, ax = plt.subplots(figsize=(10, 9), subplot_kw={'projection': ccrs.PlateCarree()})
ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())  # ä½¿ç”¨ç›¸åŒçš„è¾¹ç•Œæ¥è®¾ç½®åœ°å›¾èŒƒå›´
gdf_shape.plot(ax=ax, color='lightgray', edgecolor='black', linewidth=0.8, zorder=1)
# ç»˜åˆ¶æ’å€¼é¢ï¼ˆä»…æµ·æ´‹ï¼‰
im = ax.contourf(
    grid_lon_2d, grid_lat_2d, masked_da,
    levels=np.linspace(0, 1, 11),
    cmap='coolwarm', alpha=0.8, transform=ccrs.PlateCarree(), extend='both'
)

# ç»˜åˆ¶ç­‰å€¼çº¿ï¼ˆä»…æµ·æ´‹ï¼‰
ax.contour(
    grid_lon_2d, grid_lat_2d, masked_da,
    levels=np.linspace(0, 1, 11),
    colors='black',
    linewidths=0.3,
    linestyles='solid',
    alpha=0.5,
    transform=ccrs.PlateCarree()
)

# ç»˜åˆ¶æœ€ä½³é˜ˆå€¼çº¿ï¼ˆç»¿è‰²è™šçº¿ï¼‰
CS = ax.contour(
    grid_lon_2d, grid_lat_2d, masked_da,
    levels=[best_threshold_sheet7],
    colors='limegreen',
    linewidths=2.5,
    linestyles='dashed',
    transform=ccrs.PlateCarree()
)
ax.clabel(CS, fmt={best_threshold_sheet7: f'{best_threshold_sheet7:.2f}'}, fontsize=10,
          colors='limegreen', inline=True)

# å åŠ é‡‡æ ·ç‚¹
for _, row in df_new_output.iterrows():
    color = 'blue' if row['é¢„æµ‹ç»“æœ'] == 0 else 'red'
    ax.plot(
        row['longitude'], row['latitude'],
        marker='o', color=color, markersize=6, alpha=0.9,
        transform=ccrs.Geodetic(), zorder=5,
        markeredgecolor='white', markeredgewidth=0.8
    )

# æ ‡é¢˜
ax.set_title(f"Hypoxia probability prediction map for 2022", fontsize=18, weight='bold', pad=20)#å¹´ä»½

# ç½‘æ ¼çº¿
gl = ax.gridlines(draw_labels=True, linewidth=1.0, color='gray', alpha=0.5, linestyle='--')
gl.top_labels = False
gl.right_labels = False
gl.xlabel_style = {'size': 12}
gl.ylabel_style = {'size': 12}
gl.xformatter = LONGITUDE_FORMATTER
gl.yformatter = LATITUDE_FORMATTER
gl.xlocator = mticker.FixedLocator(np.arange(np.floor(min_lon), np.ceil(max_lon), 1))
gl.ylocator = mticker.FixedLocator(np.arange(np.floor(min_lat), np.ceil(max_lat), 1))

# é¢œè‰²æ¡
cbar = plt.colorbar(im, ax=ax, shrink=0.6, pad=0.08, aspect=20)
cbar.set_label('Hypoxia Probability', fontsize=14)
cbar.ax.tick_params(labelsize=12)

# ä¿å­˜
plt.tight_layout()
plt.savefig(map_output_interpolate_path, dpi=300, bbox_inches='tight', facecolor='white')
plt.close()
print(f"âœ… æ’å€¼åŒºåŸŸåœ°å›¾ï¼ˆä»…é™æ¸¤æµ·æµ·åŸŸï¼Œç­‰å€¼çº¿ä¸è¶Šç•Œï¼‰å·²ä¿å­˜è‡³: {map_output_interpolate_path}")

# === è®¡ç®—ä½æ°§åŒºåŸŸé¢ç§¯ï¼ˆkmÂ²ï¼‰===
print("\nğŸ“Š å¼€å§‹è®¡ç®—ä½æ°§åŒºåŸŸé¢ç§¯...")

# è·å– dx å’Œ dyï¼Œå³ç½‘æ ¼å•å…ƒåœ¨ç»åº¦å’Œçº¬åº¦æ–¹å‘ä¸Šçš„å¤§å°
dx = np.mean(np.diff(grid_lon))  # ç»åº¦æ–¹å‘ä¸Šçš„å¹³å‡å·®è·
dy = np.mean(np.diff(grid_lat))  # çº¬åº¦æ–¹å‘ä¸Šçš„å¹³å‡å·®è·

# åˆ›å»ºåŒ…å«ä½æ°§åŒºåŸŸçš„å¤šè¾¹å½¢
hypoxia_polygons = []
for i in range(grid_z.shape[0]):
    for j in range(grid_z.shape[1]):
        if not np.ma.is_masked(masked_da[i, j]) and masked_da[i, j] >= best_threshold_sheet7:
            # è·å–å››ä¸ªè§’ç‚¹çš„ç»çº¬åº¦åæ ‡
            lon_min = grid_lon_2d[i, j] - dx / 2
            lon_max = grid_lon_2d[i, j] + dx / 2
            lat_min = grid_lat_2d[i, j] - dy / 2
            lat_max = grid_lat_2d[i, j] + dy / 2

            # åˆ›å»ºå››è¾¹å½¢å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            hypoxia_polygons.append(Polygon([
                (lon_min, lat_min), (lon_max, lat_min),
                (lon_max, lat_max), (lon_min, lat_max)
            ]))

# åˆå¹¶æ‰€æœ‰å°å¤šè¾¹å½¢
if len(hypoxia_polygons) > 0:
    hypoxia_polygon = unary_union(hypoxia_polygons)

    # å°†å¤šè¾¹å½¢è½¬æ¢ä¸º GeoDataFrame å¹¶è®¾ç½®åæ ‡ç³»
    gdf_hypoxia = gpd.GeoDataFrame({'geometry': [hypoxia_polygon]}, crs="EPSG:4326")

    # è½¬æ¢åˆ°ç­‰é¢ç§¯æŠ•å½±ï¼ˆå¦‚ EPSG:6933ï¼‰
    gdf_hypoxia_area = gdf_hypoxia.to_crs("EPSG:6933")

    # è®¡ç®—é¢ç§¯ï¼ˆå•ä½ï¼šå¹³æ–¹åƒç±³ï¼‰
    total_hypoxia_area = gdf_hypoxia_area['geometry'].area.iloc[0] / 1e6
else:
    total_hypoxia_area = 0.0

total_hypoxia_area = round(total_hypoxia_area, 2)
print(f"âœ… ä½æ°§åŒºåŸŸé¢ç§¯ï¼ˆæ¦‚ç‡ â‰¥ {best_threshold_sheet7:.2f}ï¼‰: {total_hypoxia_area} kmÂ²")
